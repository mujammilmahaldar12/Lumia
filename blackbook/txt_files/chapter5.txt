CHAPTER 5
IMPLEMENTATION AND TESTING

---

5.1 Implementation Approaches

The implementation of the Lumia system follows a modern, modular, and iterative approach, leveraging a powerful stack of Python libraries to build a robust and scalable financial analysis platform. The core implementation strategies are:

- Language and Core Libraries: Python was chosen as the primary programming language due to its extensive ecosystem of libraries for data science, web development, and numerical computing. Key libraries include Pandas for data manipulation, SQLAlchemy for database interaction, and Streamlit for the user interface.

- Modular Architecture: The codebase is organized into distinct modules (collectors, models, roboadvisor, app), each with a specific responsibility. This separation of concerns simplifies development, testing, and future maintenance. For instance, the collectors module can be updated to add new data sources without affecting the roboadvisor's core logic.

- Database-First with ORM: The system uses a PostgreSQL database as its data store. The schema is managed through the SQLAlchemy Object-Relational Mapper (ORM), which maps Python classes to database tables. This approach abstracts away the raw SQL, reduces the risk of errors, and makes the code more readable and database-agnostic. Database migrations are managed by Alembic, allowing for version-controlled changes to the schema.

- Component-Based UI: The user interface is built with Streamlit, following a component-based design pattern. Reusable UI elements like metric cards and charts are encapsulated in the app/components.py module. This promotes a consistent user experience and accelerates front-end development.

- Script-Based Automation: Repetitive tasks, such as data collection, are automated using command-line scripts located in the scripts/ directory. This allows for easy scheduling and execution of background processes, like running the collectors via a cron job or a task scheduler.

5.2 Coding Details and Code Efficiency

5.2.1 Code Efficiency

Code efficiency is crucial for a data-intensive application like Lumia, especially in data processing and analytical calculations. Several techniques are employed to ensure performance:

- Vectorized Operations with Pandas: Instead of iterating through rows, analytical calculations (e.g., calculating returns, volatility) are performed using vectorized operations provided by the Pandas library. This is significantly faster as it leverages underlying C implementations.

- Efficient Database Queries: SQLAlchemy's ORM is used to construct efficient database queries. By using joins and filtering at the database level, the amount of data transferred to the application is minimized. For example, when selecting assets, filters are applied directly in the database query rather than loading all assets into memory and filtering in Python.

- Bulk Operations: When inserting or updating large amounts of data (e.g., daily prices), bulk methods like bulkinsertmappings or bulksaveobjects are preferred over inserting records one by one. This reduces the number of database round-trips and significantly improves performance.

- Lazy Loading: SQLAlchemy's relationship loading strategies are configured to use "lazy loading" by default. This means that related objects (like the daily_prices for an Asset) are only fetched from the database when they are first accessed, preventing the over-fetching of data.

- Caching: For data that does not change frequently, such as the list of available assets or historical fundamentals, caching mechanisms can be implemented. Streamlit's @st.cachedata and @st.cacheresource decorators are used to cache the results of expensive computations and data loading operations, making the UI much more responsive.

5.3 Testing Approach

A multi-layered testing approach is designed to ensure the correctness, reliability, and performance of the Lumia system. The strategy includes unit, integration, and performance testing.

5.3.1 Unit Testing

Unit tests focus on testing the smallest, isolated parts of the application, such as individual functions or methods. The goal is to verify that each component works correctly on its own. A framework like Pytest would be used for this.

- Roboadvisor Logic: Test the portfolio optimizer with a fixed set of inputs (returns, covariances) to ensure it produces the expected optimal weights. Test the asset scoring functions to verify they calculate scores correctly.
- Collectors: Mock the external API calls to test the data parsing and transformation logic of each collector. For example, provide a sample JSON response from a news API and assert that the collect_news module correctly extracts the headline, date, and content.
- Utilities: Test utility functions, such as the currency formatter in the Streamlit app, with various inputs to ensure they handle all edge cases.

5.3.2 Integrated Testing

Integration tests verify that different modules of the application work together as intended. These tests are more complex and focus on the interactions between components.

- Data Pipeline: Test the complete flow from running a data collector to verifying that the data is correctly stored in the database. This involves running a collector script against a test database and then querying the database to assert that the records were created with the correct values.
- Recommendation Engine: Test the integration between the userprofile, assetselector, and recommender modules. This test would simulate user input, generate a profile, and verify that the final recommendation is consistent with the user's risk tolerance and the assets selected.
- App and Database: Test the interaction between the Streamlit application and the database. This involves starting the app, having it query the test database, and asserting that the data displayed in the UI is correct.

5.3.3 Performance Testing

Performance testing focuses on evaluating the system's speed, responsiveness, and stability under load.

- Database Query Performance: Analyze the execution time of critical database queries, especially those used in the asset_selector and for loading historical data for the UI. Tools like EXPLAIN ANALYZE in PostgreSQL can be used to identify slow queries and optimize them, for example, by adding indexes.
- API Collector Performance: Measure the time taken by data collectors to fetch data from external APIs. This helps identify bottlenecks and can inform decisions about using concurrent requests to speed up data acquisition.
- Application Load Testing: Use tools like Locust or JMeter to simulate multiple users accessing the Streamlit application simultaneously. This helps measure the application's response time under load and identify any performance degradation.

5.4 Modifications and Improvements

The current Lumia system provides a solid foundation, but several improvements can be made in the future:

- Enhanced AI/ML Models: Integrate more advanced machine learning models for predicting asset returns or generating market sentiment scores. Time-series forecasting models like ARIMA or LSTM could be used to complement the existing quantitative models.
- Real-Time Data: Implement WebSocket connections to data providers for real-time price updates in the user interface, providing a more dynamic experience.
- Expanded Asset Classes: Add support for more asset classes, such as bonds, commodities, and real estate, to provide more comprehensive portfolio diversification options.
- Robust User Management: Implement a full-fledged user authentication and management system to support multiple users securely.
- Automated Backtesting Engine: Build a dedicated module for rigorously backtesting portfolio strategies against historical data, allowing for the evaluation and comparison of different algorithms.
- CI/CD Pipeline: Set up a Continuous Integration/Continuous Deployment (CI/CD) pipeline to automate testing and deployment, ensuring that new changes are automatically validated and deployed to production.

5.5 Test Cases

Below are examples of specific test cases that would be implemented for the Lumia system.

Test Case 1: Unit Test for stocks_manager
- Objective: Verify that the stocks_manager correctly identifies and adds a new stock to the database.
- Procedure:
1. Mock the API call that fetches the list of stocks.
2. Run the stocks_manager collector.
3. Assert that the Asset table in the test database now contains the new stock with the correct symbol, name, and type.

Test Case 2: Unit Test for optimizer
- Objective: Ensure the Mean-Variance Optimizer calculates the correct portfolio weights.
- Procedure:
1. Provide a predefined 2-asset covariance matrix and expected returns.
2. Run the optimizer function.
3. Assert that the returned weights for the two assets match the mathematically expected optimal weights for a given risk level.

Test Case 3: Integration Test for News Collection and Sentiment Analysis
- Objective: Verify that news articles are collected, stored, and analyzed correctly.
- Procedure:
1. Run the collect_news script for a specific asset (e.g., 'AAPL').
2. Query the news_articles table to confirm that articles have been added.
3. Check that the sentiment column for the new articles contains a plausible floating-point value.

Test Case 4: Integration Test for Full Recommendation Flow
- Objective: Test the end-to-end process of generating a recommendation.
- Procedure:
1. Populate a test database with a set of assets and their historical prices.
2. Simulate a user submitting a "high-risk" profile in the UI.
3. Trigger the recommendation generation process.
4. Assert that the final recommended portfolio contains a higher allocation to volatile assets (like stocks) compared to a "low-risk" profile.

Test Case 5: Performance Test for Dashboard Loading
- Objective: Ensure the main dashboard loads within an acceptable time frame.
- Procedure:
1. Populate the database with a large volume of data (e.g., 1,000 assets with 5 years of daily prices).
2. Start the Streamlit application.
3. Use a browser automation tool to measure the time from navigating to the app's URL to the full rendering of the main dashboard.
4. Assert that the load time is below a predefined threshold (e.g., 3 seconds).